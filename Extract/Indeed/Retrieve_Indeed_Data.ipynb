{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#URL creation for webscrapping \n",
    "eg : https://www.indeed.com/jobs?q=python+pandas+Data+Scientist&l=California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=python+pandas+Data+Scientist&l=Massachusetts\n"
     ]
    }
   ],
   "source": [
    "#Obtaining an instance of browser\n",
    "browser = webdriver.Chrome('windows/chromedriver')\n",
    "#job_type (\"Data+Scientist\" or \"Data+Engineer\" or \"Data+Analyst\"]\n",
    "#job_state (\"Washington\" or \"New+York\" or \"Massachusetts\" or \"Ohio\" or \"California\")\n",
    "\n",
    "#Variable declarion\n",
    "job_type = \"Data+Scientist\"\n",
    "job_state = \"Massachusetts\"\n",
    "skills = \"python+pandas+\"\n",
    "job_criteria = skills+job_type\n",
    "url = \"https://www.indeed.com/jobs?q=\" + job_criteria + \"&l=\"+job_state\n",
    "print(url)\n",
    "browser.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Pop-Up Found.\n",
      "Lenght of list is 12\n",
      "Cambridge Mobile Telematics\n",
      "Next »\n",
      "Clicking Next 1\n",
      "Lenght of list is 23\n",
      "Qtron Investments\n",
      "Next »\n",
      "Clicking Next 2\n",
      "No Pop-Up Found.\n",
      "Lenght of list is 34\n",
      "MassMutual\n",
      "Next »\n",
      "Clicking Next 3\n",
      "No Pop-Up Found.\n",
      "Lenght of list is 44\n",
      "Indigo\n",
      "Next »\n",
      "Clicking Next 4\n",
      "No Pop-Up Found.\n",
      "Lenght of list is 45\n",
      "DataRobot\n",
      "Scraping Complete\n"
     ]
    }
   ],
   "source": [
    "#Creating a List to hold all the job openings here\n",
    "job_opening = []\n",
    "x = 0\n",
    "scrapping_bool = True\n",
    "while scrapping_bool:\n",
    "    x +=1\n",
    "    # HTML object\n",
    "    html = browser.page_source\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Retrieve all elements that have job opening information\n",
    "    job_listing = soup.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "    #print(f\"this is the no of job listing on webpage {x}\")\n",
    "   # print(f\"this is the no of job listing obtained {len(job_title)}\")\n",
    "\n",
    "    for listing in job_listing:\n",
    "        \n",
    "        title_detail = listing.find('div',class_='title')\n",
    "        title = title_detail.a['title']\n",
    "        \n",
    "        company_detail = listing.find('div',class_='sjcl')\n",
    "        company_name = company_detail.span.text.strip()\n",
    "        \n",
    "        handle_loc = listing.find('div',class_='recJobLoc')\n",
    "        location = handle_loc['data-rc-loc'].strip()\n",
    "        job_summary = listing.find('div',class_='summary').text.strip()\n",
    "        #Creating a dictionary object for each job opening   \n",
    "        dict_jobopening = {\"job_title\": title,\"company_name\": company_name,\"location\":location,\n",
    "                          \"job_summary\": job_summary}#,\"reviews\": reviews,\"ratings\": ratings}\n",
    "        job_opening.append(dict_jobopening)\n",
    "        \n",
    "        time.sleep(1)\n",
    "       \n",
    "    try:\n",
    "        #alert = browser.switch_to_alert()\n",
    "        #alert.dismiss()\n",
    "        #To click on the pop-ups that keeps popping up on every page almost\n",
    "        browser.find_element_by_partial_link_text('No, thanks').click() \n",
    "        time.sleep(1)\n",
    "\n",
    "    except:\n",
    "        print(\"No Pop-Up Found.\")\n",
    "\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        print(f\"Lenght of list is {len(job_opening)}\")\n",
    "        time.sleep(1)\n",
    "        print(company_name)\n",
    "        #Clicking the next link, checking if the word is not a match in the name of the company eg Nextdoor\n",
    "        nextElem = browser.find_element_by_partial_link_text('Next')\n",
    "        print(nextElem.text)\n",
    "        if(nextElem.text == \"Next »\"):\n",
    "            nextElem.click()\n",
    "            print(f\"Clicking Next {x}\")\n",
    "            time.sleep(1)\n",
    "     \n",
    "    except NoSuchElementException:\n",
    "\n",
    "        print(\"Scraping Complete\")\n",
    "        scrapping_bool = False\n",
    "        break\n",
    "            \n",
    "#closing the browser window    \n",
    "browser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iteris, Inc.</td>\n",
       "      <td>Experience or interest in map based data visua...</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systems &amp; Technology Research</td>\n",
       "      <td>Your expertise as a data scientist will aid a ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Woburn, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient AI</td>\n",
       "      <td>Synthesize research data, turning data to acti...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Leverage data and business principles to solve...</td>\n",
       "      <td>Data Scientist, Infrastructure Strategy Intern</td>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harvard University</td>\n",
       "      <td>The data scientist will collaborate with other...</td>\n",
       "      <td>Data Scientist, Media Manipulation</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    company_name  \\\n",
       "0                   Iteris, Inc.   \n",
       "1  Systems & Technology Research   \n",
       "2                    Gradient AI   \n",
       "3                       Facebook   \n",
       "4             Harvard University   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  Experience or interest in map based data visua...   \n",
       "1  Your expertise as a data scientist will aid a ...   \n",
       "2  Synthesize research data, turning data to acti...   \n",
       "3  Leverage data and business principles to solve...   \n",
       "4  The data scientist will collaborate with other...   \n",
       "\n",
       "                                        job_title       location  \n",
       "0                              Software Developer  United States  \n",
       "1                                  Data Scientist     Woburn, MA  \n",
       "2                                  Data Scientist  Cambridge, MA  \n",
       "3  Data Scientist, Infrastructure Strategy Intern     Boston, MA  \n",
       "4              Data Scientist, Media Manipulation  Cambridge, MA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_opening_df = pd.DataFrame(job_opening)\n",
    "job_opening_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with split value columns \n",
    "new = job_opening_df[\"location\"].str.split(\",\", n = 1, expand = True) \n",
    "#print(new)  \n",
    "# making separate first name column from new data frame \n",
    "job_opening_df[\"City\"]= new[0] \n",
    "  \n",
    "# making separate last name column from new data frame \n",
    "job_opening_df[\"State\"]= new[1] \n",
    "  \n",
    "# Dropping old Name columns \n",
    "job_opening_df.drop(columns =[\"location\"], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_opening_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Massachusetts_outputData+Scientist.xlsx\n"
     ]
    }
   ],
   "source": [
    "outFileName = job_state+\"_output\"+job_type+\".xlsx\"\n",
    "print(outFileName)\n",
    "job_opening_df.to_excel(\"output/\"+outFileName)  \n",
    "#job_opening_df.to_csv(\"output/\"+outFileName, sep='\\t', index=False, header=True, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
